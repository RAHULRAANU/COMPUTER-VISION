{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "R73QshQwjeMM"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "l7GwxLRIkMLR"
   },
   "outputs": [],
   "source": [
    "zip_ref = zipfile.ZipFile(r'/content/dataset.zip', 'r') #Opens the zip file in read mode\n",
    "zip_ref.extractall('/tmp') #Extracts the files into the /tmp folder\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6RP_RTePkMN2",
    "outputId": "faca7c2f-752f-440f-f1cb-64f97beff0f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting Progress\n",
      "  Downloading progress-1.6.tar.gz (7.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: Progress\n",
      "  Building wheel for Progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for Progress: filename=progress-1.6-py3-none-any.whl size=9630 sha256=8490e0dfcfbee065a5c2944dfdfb93b74c2f5bab0e97201b1145fa8a665ed44a\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/9b/0a/a78ff56725af3ef70792f9ed0f8dbbc4c0315edc62cbc4a6b8\n",
      "Successfully built Progress\n",
      "Installing collected packages: Progress\n",
      "Successfully installed Progress-1.6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Import Necessary Library\n",
    "\n",
    "!pip install Progress\n",
    "\n",
    "\n",
    "from IPython.display import Image  \n",
    "import shutil\n",
    "import os\n",
    "from random import choice\n",
    "\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import IntProgress\n",
    "import progress \n",
    "\n",
    "import os\n",
    "import glob as glob\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import requests\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 2529\n",
    "np.random.seed(SEED)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4ezA3OxkMQO",
    "outputId": "84c2a201-199a-4932-fc2b-f0856141d413"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Package(s) not found: tensorflow-gpu\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip show tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GomjxP9tkMS5",
    "outputId": "bd77d561-d048-47cf-a6aa-8f5668178a75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version :  1.13.1+cu116\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.get_device_properties(0)\n",
    "print(\"torch version : \",torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4B1dkUmqkMY4",
    "outputId": "0df251fb-26c3-4833-a272-92e2e2f0245c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.zip  sample_data\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H8IhmY8dkMbm",
    "outputId": "508e3cfd-931c-4f4c-d75b-4c0c2beeb185"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.zip  sample_data\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3TqT0d7kMd9",
    "outputId": "8afb579f-a295-47b5-b47c-2aa3eb638f53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 15291, done.\u001b[K\n",
      "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
      "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
      "remote: Total 15291 (delta 0), reused 1 (delta 0), pack-reused 15287\u001b[K\n",
      "Receiving objects: 100% (15291/15291), 14.19 MiB | 13.38 MiB/s, done.\n",
      "Resolving deltas: 100% (10483/10483), done.\n"
     ]
    }
   ],
   "source": [
    "# cloning the yolo repository\n",
    "\n",
    "# !git clone https://github.com/ultralytics/yolov5.git\n",
    "\n",
    "if not os.path.exists('/home/ubuntu/Number_detect_from_license_plate/yolov5'):\n",
    "    !git clone https://github.com/ultralytics/yolov5.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1vmurdBzkMgi",
    "outputId": "986c5a05-db73-4839-aa9d-5996564b0940"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.zip  sample_data  yolov5\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5f8SiW8BkMjJ",
    "outputId": "fb7cced3-eeaa-4370-fc62-11273b9c7691"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/yolov5\n",
      "/content/yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5/\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gFlTmF82pk-a",
    "outputId": "bd50cfd9-c7c0-4106-a531-8fcab7f2c5d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmarks.py\t data\t       hubconf.py  README.zh-CN.md   train.py\n",
      "CITATION.cff\t dataset.yaml  LICENSE\t   requirements.txt  tutorial.ipynb\n",
      "classify\t detect.py     models\t   segment\t     utils\n",
      "CONTRIBUTING.md  export.py     README.md   setup.cfg\t     val.py\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iIWEXiUqplA7",
    "outputId": "9ed0a35e-b327-4541-d5be-058da7c31474"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting gitpython>=3.1.30\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (3.5.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (1.22.4)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (4.6.0.66)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (8.4.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (5.4.8)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 11)) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 12)) (2.25.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (1.10.1)\n",
      "Collecting thop>=0.1.1\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 15)) (1.13.1+cu116)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 16)) (0.14.1+cu116)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 17)) (4.65.0)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 21)) (2.11.2)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 26)) (1.3.5)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 27)) (0.11.2)\n",
      "Collecting setuptools>=65.5.1\n",
      "  Downloading setuptools-67.6.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (4.39.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (23.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.14)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2022.12.7)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (4.5.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.16.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.6.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.4.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.38.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.4.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.51.3)\n",
      "Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.19.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.2.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 26)) (2022.7.1)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.15.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 21)) (6.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 21)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 21)) (3.2.2)\n",
      "Installing collected packages: smmap, setuptools, thop, gitdb, gitpython\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 57.4.0\n",
      "    Uninstalling setuptools-57.4.0:\n",
      "      Successfully uninstalled setuptools-57.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
      "cvxpy 1.2.3 requires setuptools<=64.0.2, but you have setuptools 67.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed gitdb-4.0.10 gitpython-3.1.31 setuptools-67.6.0 smmap-5.0.0 thop-0.1.1.post2209072238\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ho5tpG5dplDp",
    "outputId": "202db43d-c1e9-4971-c368-010aa920e843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/yolov5/yolov5x.pt, cfg=, data=/content/yolov5/dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=2, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=1000, bucket=, cache=ram, image_weights=False, device=, multi_scale=True, single_cls=False, optimizer=SGD, sync_bn=False, workers=4, project=runs/train, name={colab_result}, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=20, freeze=[17], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
      "YOLOv5 ğŸš€ v7.0-117-g85f6019 Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=3\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ğŸš€ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ğŸš€ runs in Comet\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
      "100% 755k/755k [00:00<00:00, 87.6MB/s]\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x.pt to /content/yolov5/yolov5x.pt...\n",
      "100% 166M/166M [00:19<00:00, 8.84MB/s]\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=36\n",
      "Overriding model.yaml anchors with anchors=3\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
      "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
      "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
      "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
      "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
      "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
      "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
      "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
      "  8                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
      "  9                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
      " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
      " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
      " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
      " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
      " 24      [17, 20, 23]  1    275889  models.yolo.Detect                      [36, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [320, 640, 1280]]\n",
      "Model summary: 445 layers, 86453329 parameters, 86453329 gradients, 205.4 GFLOPs\n",
      "\n",
      "Transferred 738/745 items from /content/yolov5/yolov5x.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "freezing model.0.conv.weight\n",
      "freezing model.0.bn.weight\n",
      "freezing model.0.bn.bias\n",
      "freezing model.1.conv.weight\n",
      "freezing model.1.bn.weight\n",
      "freezing model.1.bn.bias\n",
      "freezing model.2.cv1.conv.weight\n",
      "freezing model.2.cv1.bn.weight\n",
      "freezing model.2.cv1.bn.bias\n",
      "freezing model.2.cv2.conv.weight\n",
      "freezing model.2.cv2.bn.weight\n",
      "freezing model.2.cv2.bn.bias\n",
      "freezing model.2.cv3.conv.weight\n",
      "freezing model.2.cv3.bn.weight\n",
      "freezing model.2.cv3.bn.bias\n",
      "freezing model.2.m.0.cv1.conv.weight\n",
      "freezing model.2.m.0.cv1.bn.weight\n",
      "freezing model.2.m.0.cv1.bn.bias\n",
      "freezing model.2.m.0.cv2.conv.weight\n",
      "freezing model.2.m.0.cv2.bn.weight\n",
      "freezing model.2.m.0.cv2.bn.bias\n",
      "freezing model.2.m.1.cv1.conv.weight\n",
      "freezing model.2.m.1.cv1.bn.weight\n",
      "freezing model.2.m.1.cv1.bn.bias\n",
      "freezing model.2.m.1.cv2.conv.weight\n",
      "freezing model.2.m.1.cv2.bn.weight\n",
      "freezing model.2.m.1.cv2.bn.bias\n",
      "freezing model.2.m.2.cv1.conv.weight\n",
      "freezing model.2.m.2.cv1.bn.weight\n",
      "freezing model.2.m.2.cv1.bn.bias\n",
      "freezing model.2.m.2.cv2.conv.weight\n",
      "freezing model.2.m.2.cv2.bn.weight\n",
      "freezing model.2.m.2.cv2.bn.bias\n",
      "freezing model.2.m.3.cv1.conv.weight\n",
      "freezing model.2.m.3.cv1.bn.weight\n",
      "freezing model.2.m.3.cv1.bn.bias\n",
      "freezing model.2.m.3.cv2.conv.weight\n",
      "freezing model.2.m.3.cv2.bn.weight\n",
      "freezing model.2.m.3.cv2.bn.bias\n",
      "freezing model.3.conv.weight\n",
      "freezing model.3.bn.weight\n",
      "freezing model.3.bn.bias\n",
      "freezing model.4.cv1.conv.weight\n",
      "freezing model.4.cv1.bn.weight\n",
      "freezing model.4.cv1.bn.bias\n",
      "freezing model.4.cv2.conv.weight\n",
      "freezing model.4.cv2.bn.weight\n",
      "freezing model.4.cv2.bn.bias\n",
      "freezing model.4.cv3.conv.weight\n",
      "freezing model.4.cv3.bn.weight\n",
      "freezing model.4.cv3.bn.bias\n",
      "freezing model.4.m.0.cv1.conv.weight\n",
      "freezing model.4.m.0.cv1.bn.weight\n",
      "freezing model.4.m.0.cv1.bn.bias\n",
      "freezing model.4.m.0.cv2.conv.weight\n",
      "freezing model.4.m.0.cv2.bn.weight\n",
      "freezing model.4.m.0.cv2.bn.bias\n",
      "freezing model.4.m.1.cv1.conv.weight\n",
      "freezing model.4.m.1.cv1.bn.weight\n",
      "freezing model.4.m.1.cv1.bn.bias\n",
      "freezing model.4.m.1.cv2.conv.weight\n",
      "freezing model.4.m.1.cv2.bn.weight\n",
      "freezing model.4.m.1.cv2.bn.bias\n",
      "freezing model.4.m.2.cv1.conv.weight\n",
      "freezing model.4.m.2.cv1.bn.weight\n",
      "freezing model.4.m.2.cv1.bn.bias\n",
      "freezing model.4.m.2.cv2.conv.weight\n",
      "freezing model.4.m.2.cv2.bn.weight\n",
      "freezing model.4.m.2.cv2.bn.bias\n",
      "freezing model.4.m.3.cv1.conv.weight\n",
      "freezing model.4.m.3.cv1.bn.weight\n",
      "freezing model.4.m.3.cv1.bn.bias\n",
      "freezing model.4.m.3.cv2.conv.weight\n",
      "freezing model.4.m.3.cv2.bn.weight\n",
      "freezing model.4.m.3.cv2.bn.bias\n",
      "freezing model.4.m.4.cv1.conv.weight\n",
      "freezing model.4.m.4.cv1.bn.weight\n",
      "freezing model.4.m.4.cv1.bn.bias\n",
      "freezing model.4.m.4.cv2.conv.weight\n",
      "freezing model.4.m.4.cv2.bn.weight\n",
      "freezing model.4.m.4.cv2.bn.bias\n",
      "freezing model.4.m.5.cv1.conv.weight\n",
      "freezing model.4.m.5.cv1.bn.weight\n",
      "freezing model.4.m.5.cv1.bn.bias\n",
      "freezing model.4.m.5.cv2.conv.weight\n",
      "freezing model.4.m.5.cv2.bn.weight\n",
      "freezing model.4.m.5.cv2.bn.bias\n",
      "freezing model.4.m.6.cv1.conv.weight\n",
      "freezing model.4.m.6.cv1.bn.weight\n",
      "freezing model.4.m.6.cv1.bn.bias\n",
      "freezing model.4.m.6.cv2.conv.weight\n",
      "freezing model.4.m.6.cv2.bn.weight\n",
      "freezing model.4.m.6.cv2.bn.bias\n",
      "freezing model.4.m.7.cv1.conv.weight\n",
      "freezing model.4.m.7.cv1.bn.weight\n",
      "freezing model.4.m.7.cv1.bn.bias\n",
      "freezing model.4.m.7.cv2.conv.weight\n",
      "freezing model.4.m.7.cv2.bn.weight\n",
      "freezing model.4.m.7.cv2.bn.bias\n",
      "freezing model.5.conv.weight\n",
      "freezing model.5.bn.weight\n",
      "freezing model.5.bn.bias\n",
      "freezing model.6.cv1.conv.weight\n",
      "freezing model.6.cv1.bn.weight\n",
      "freezing model.6.cv1.bn.bias\n",
      "freezing model.6.cv2.conv.weight\n",
      "freezing model.6.cv2.bn.weight\n",
      "freezing model.6.cv2.bn.bias\n",
      "freezing model.6.cv3.conv.weight\n",
      "freezing model.6.cv3.bn.weight\n",
      "freezing model.6.cv3.bn.bias\n",
      "freezing model.6.m.0.cv1.conv.weight\n",
      "freezing model.6.m.0.cv1.bn.weight\n",
      "freezing model.6.m.0.cv1.bn.bias\n",
      "freezing model.6.m.0.cv2.conv.weight\n",
      "freezing model.6.m.0.cv2.bn.weight\n",
      "freezing model.6.m.0.cv2.bn.bias\n",
      "freezing model.6.m.1.cv1.conv.weight\n",
      "freezing model.6.m.1.cv1.bn.weight\n",
      "freezing model.6.m.1.cv1.bn.bias\n",
      "freezing model.6.m.1.cv2.conv.weight\n",
      "freezing model.6.m.1.cv2.bn.weight\n",
      "freezing model.6.m.1.cv2.bn.bias\n",
      "freezing model.6.m.2.cv1.conv.weight\n",
      "freezing model.6.m.2.cv1.bn.weight\n",
      "freezing model.6.m.2.cv1.bn.bias\n",
      "freezing model.6.m.2.cv2.conv.weight\n",
      "freezing model.6.m.2.cv2.bn.weight\n",
      "freezing model.6.m.2.cv2.bn.bias\n",
      "freezing model.6.m.3.cv1.conv.weight\n",
      "freezing model.6.m.3.cv1.bn.weight\n",
      "freezing model.6.m.3.cv1.bn.bias\n",
      "freezing model.6.m.3.cv2.conv.weight\n",
      "freezing model.6.m.3.cv2.bn.weight\n",
      "freezing model.6.m.3.cv2.bn.bias\n",
      "freezing model.6.m.4.cv1.conv.weight\n",
      "freezing model.6.m.4.cv1.bn.weight\n",
      "freezing model.6.m.4.cv1.bn.bias\n",
      "freezing model.6.m.4.cv2.conv.weight\n",
      "freezing model.6.m.4.cv2.bn.weight\n",
      "freezing model.6.m.4.cv2.bn.bias\n",
      "freezing model.6.m.5.cv1.conv.weight\n",
      "freezing model.6.m.5.cv1.bn.weight\n",
      "freezing model.6.m.5.cv1.bn.bias\n",
      "freezing model.6.m.5.cv2.conv.weight\n",
      "freezing model.6.m.5.cv2.bn.weight\n",
      "freezing model.6.m.5.cv2.bn.bias\n",
      "freezing model.6.m.6.cv1.conv.weight\n",
      "freezing model.6.m.6.cv1.bn.weight\n",
      "freezing model.6.m.6.cv1.bn.bias\n",
      "freezing model.6.m.6.cv2.conv.weight\n",
      "freezing model.6.m.6.cv2.bn.weight\n",
      "freezing model.6.m.6.cv2.bn.bias\n",
      "freezing model.6.m.7.cv1.conv.weight\n",
      "freezing model.6.m.7.cv1.bn.weight\n",
      "freezing model.6.m.7.cv1.bn.bias\n",
      "freezing model.6.m.7.cv2.conv.weight\n",
      "freezing model.6.m.7.cv2.bn.weight\n",
      "freezing model.6.m.7.cv2.bn.bias\n",
      "freezing model.6.m.8.cv1.conv.weight\n",
      "freezing model.6.m.8.cv1.bn.weight\n",
      "freezing model.6.m.8.cv1.bn.bias\n",
      "freezing model.6.m.8.cv2.conv.weight\n",
      "freezing model.6.m.8.cv2.bn.weight\n",
      "freezing model.6.m.8.cv2.bn.bias\n",
      "freezing model.6.m.9.cv1.conv.weight\n",
      "freezing model.6.m.9.cv1.bn.weight\n",
      "freezing model.6.m.9.cv1.bn.bias\n",
      "freezing model.6.m.9.cv2.conv.weight\n",
      "freezing model.6.m.9.cv2.bn.weight\n",
      "freezing model.6.m.9.cv2.bn.bias\n",
      "freezing model.6.m.10.cv1.conv.weight\n",
      "freezing model.6.m.10.cv1.bn.weight\n",
      "freezing model.6.m.10.cv1.bn.bias\n",
      "freezing model.6.m.10.cv2.conv.weight\n",
      "freezing model.6.m.10.cv2.bn.weight\n",
      "freezing model.6.m.10.cv2.bn.bias\n",
      "freezing model.6.m.11.cv1.conv.weight\n",
      "freezing model.6.m.11.cv1.bn.weight\n",
      "freezing model.6.m.11.cv1.bn.bias\n",
      "freezing model.6.m.11.cv2.conv.weight\n",
      "freezing model.6.m.11.cv2.bn.weight\n",
      "freezing model.6.m.11.cv2.bn.bias\n",
      "freezing model.7.conv.weight\n",
      "freezing model.7.bn.weight\n",
      "freezing model.7.bn.bias\n",
      "freezing model.8.cv1.conv.weight\n",
      "freezing model.8.cv1.bn.weight\n",
      "freezing model.8.cv1.bn.bias\n",
      "freezing model.8.cv2.conv.weight\n",
      "freezing model.8.cv2.bn.weight\n",
      "freezing model.8.cv2.bn.bias\n",
      "freezing model.8.cv3.conv.weight\n",
      "freezing model.8.cv3.bn.weight\n",
      "freezing model.8.cv3.bn.bias\n",
      "freezing model.8.m.0.cv1.conv.weight\n",
      "freezing model.8.m.0.cv1.bn.weight\n",
      "freezing model.8.m.0.cv1.bn.bias\n",
      "freezing model.8.m.0.cv2.conv.weight\n",
      "freezing model.8.m.0.cv2.bn.weight\n",
      "freezing model.8.m.0.cv2.bn.bias\n",
      "freezing model.8.m.1.cv1.conv.weight\n",
      "freezing model.8.m.1.cv1.bn.weight\n",
      "freezing model.8.m.1.cv1.bn.bias\n",
      "freezing model.8.m.1.cv2.conv.weight\n",
      "freezing model.8.m.1.cv2.bn.weight\n",
      "freezing model.8.m.1.cv2.bn.bias\n",
      "freezing model.8.m.2.cv1.conv.weight\n",
      "freezing model.8.m.2.cv1.bn.weight\n",
      "freezing model.8.m.2.cv1.bn.bias\n",
      "freezing model.8.m.2.cv2.conv.weight\n",
      "freezing model.8.m.2.cv2.bn.weight\n",
      "freezing model.8.m.2.cv2.bn.bias\n",
      "freezing model.8.m.3.cv1.conv.weight\n",
      "freezing model.8.m.3.cv1.bn.weight\n",
      "freezing model.8.m.3.cv1.bn.bias\n",
      "freezing model.8.m.3.cv2.conv.weight\n",
      "freezing model.8.m.3.cv2.bn.weight\n",
      "freezing model.8.m.3.cv2.bn.bias\n",
      "freezing model.9.cv1.conv.weight\n",
      "freezing model.9.cv1.bn.weight\n",
      "freezing model.9.cv1.bn.bias\n",
      "freezing model.9.cv2.conv.weight\n",
      "freezing model.9.cv2.bn.weight\n",
      "freezing model.9.cv2.bn.bias\n",
      "freezing model.10.conv.weight\n",
      "freezing model.10.bn.weight\n",
      "freezing model.10.bn.bias\n",
      "freezing model.13.cv1.conv.weight\n",
      "freezing model.13.cv1.bn.weight\n",
      "freezing model.13.cv1.bn.bias\n",
      "freezing model.13.cv2.conv.weight\n",
      "freezing model.13.cv2.bn.weight\n",
      "freezing model.13.cv2.bn.bias\n",
      "freezing model.13.cv3.conv.weight\n",
      "freezing model.13.cv3.bn.weight\n",
      "freezing model.13.cv3.bn.bias\n",
      "freezing model.13.m.0.cv1.conv.weight\n",
      "freezing model.13.m.0.cv1.bn.weight\n",
      "freezing model.13.m.0.cv1.bn.bias\n",
      "freezing model.13.m.0.cv2.conv.weight\n",
      "freezing model.13.m.0.cv2.bn.weight\n",
      "freezing model.13.m.0.cv2.bn.bias\n",
      "freezing model.13.m.1.cv1.conv.weight\n",
      "freezing model.13.m.1.cv1.bn.weight\n",
      "freezing model.13.m.1.cv1.bn.bias\n",
      "freezing model.13.m.1.cv2.conv.weight\n",
      "freezing model.13.m.1.cv2.bn.weight\n",
      "freezing model.13.m.1.cv2.bn.bias\n",
      "freezing model.13.m.2.cv1.conv.weight\n",
      "freezing model.13.m.2.cv1.bn.weight\n",
      "freezing model.13.m.2.cv1.bn.bias\n",
      "freezing model.13.m.2.cv2.conv.weight\n",
      "freezing model.13.m.2.cv2.bn.weight\n",
      "freezing model.13.m.2.cv2.bn.bias\n",
      "freezing model.13.m.3.cv1.conv.weight\n",
      "freezing model.13.m.3.cv1.bn.weight\n",
      "freezing model.13.m.3.cv1.bn.bias\n",
      "freezing model.13.m.3.cv2.conv.weight\n",
      "freezing model.13.m.3.cv2.bn.weight\n",
      "freezing model.13.m.3.cv2.bn.bias\n",
      "freezing model.14.conv.weight\n",
      "freezing model.14.bn.weight\n",
      "freezing model.14.bn.bias\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 123 weight(decay=0.0), 126 weight(decay=0.0005), 126 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /tmp/dataset/train/labels... 892 images, 19 backgrounds, 0 corrupt: 100% 910/910 [00:00<00:00, 2036.24it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /tmp/dataset/train/labels.cache\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.4GB ram): 100% 910/910 [00:01<00:00, 821.87it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /tmp/dataset/val/labels... 248 images, 0 backgrounds, 0 corrupt: 100% 248/248 [00:00<00:00, 511.74it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /tmp/dataset/val/labels.cache\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset âš ï¸, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 8548 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9237: 100% 1000/1000 [00:01<00:00, 511.18it/s]\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 9.00 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.747/0.924-mean/best, past_thr=0.747-mean: 42,68, 34,88, 43,83, 49,82, 44,101, 51,90, 51,112, 48,151, 69,123\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone âœ… (optional: update model *.yaml to use these anchors in the future)\n",
      "Plotting labels to runs/evolve/{colab_result}/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/evolve/{colab_result}\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/99      2.06G    0.08843     0.1813    0.08816         48        544: 100% 455/455 [01:03<00:00,  7.14it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/99      2.06G    0.07077     0.1404    0.08045         42        768: 100% 455/455 [00:57<00:00,  7.92it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/99      2.06G    0.07048     0.1413    0.07883         27        896: 100% 455/455 [00:58<00:00,  7.75it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/99      2.06G    0.06392     0.1344    0.07817         28        928: 100% 455/455 [00:57<00:00,  7.93it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/99      2.06G     0.0568     0.1284    0.07754         32        736: 100% 455/455 [00:58<00:00,  7.83it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/99      2.06G     0.0506     0.1311    0.07639         21        608: 100% 455/455 [00:56<00:00,  8.04it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/99      2.06G     0.0487     0.1272    0.07533         26        960: 100% 455/455 [00:58<00:00,  7.84it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/99      2.06G    0.04783     0.1242    0.07418         42        800: 100% 455/455 [00:57<00:00,  7.88it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/99      2.06G    0.04625     0.1212     0.0723         48        544: 100% 455/455 [00:57<00:00,  7.96it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/99      2.06G    0.04371     0.1206    0.07082         41        672: 100% 455/455 [00:57<00:00,  7.86it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/99      2.06G    0.04307     0.1203    0.06893         43        864: 100% 455/455 [00:57<00:00,  7.85it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/99      2.06G    0.04125     0.1172    0.06722         18        704: 100% 455/455 [00:59<00:00,  7.63it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/99      2.06G    0.04131      0.118    0.06543         37        480: 100% 455/455 [00:58<00:00,  7.84it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/99      2.06G    0.04197      0.121    0.06336         21        832: 100% 455/455 [01:00<00:00,  7.57it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/99      2.06G    0.04195     0.1152     0.0614         26        320: 100% 455/455 [00:57<00:00,  7.90it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/99      2.06G    0.04073     0.1211    0.05982         41        864: 100% 455/455 [00:59<00:00,  7.62it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/99      2.06G    0.03944     0.1121    0.05767         34        736: 100% 455/455 [00:59<00:00,  7.68it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/99      2.06G     0.0393     0.1144    0.05643         18        320: 100% 455/455 [00:59<00:00,  7.66it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/99      2.06G     0.0396     0.1201     0.0547         64        416: 100% 455/455 [00:57<00:00,  7.86it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/99      2.06G    0.03968     0.1166    0.05293         31        512: 100% 455/455 [01:00<00:00,  7.57it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/99      2.06G    0.03861     0.1173    0.05074         40        640: 100% 455/455 [00:57<00:00,  7.92it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      21/99      2.06G    0.03935     0.1113    0.04982         29        544: 100% 455/455 [00:58<00:00,  7.78it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      22/99      2.06G    0.03922     0.1129    0.04852         32        832: 100% 455/455 [00:58<00:00,  7.83it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      23/99      2.06G    0.03887     0.1166     0.0468         45        736: 100% 455/455 [00:57<00:00,  7.97it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      24/99      2.06G    0.03732     0.1112    0.04531         57        384: 100% 455/455 [01:00<00:00,  7.56it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      25/99      2.06G    0.03825     0.1138    0.04454         23        512: 100% 455/455 [00:57<00:00,  7.96it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      26/99      2.06G    0.03718     0.1077    0.04353         19        896: 100% 455/455 [00:58<00:00,  7.72it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      27/99      2.06G    0.03667     0.1073    0.04189         35        704: 100% 455/455 [00:57<00:00,  7.85it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      28/99      2.06G    0.03674     0.1084    0.04059         14        896: 100% 455/455 [00:59<00:00,  7.67it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      29/99      2.06G    0.03609      0.108    0.03948         23        960: 100% 455/455 [00:58<00:00,  7.83it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      30/99      2.06G     0.0379      0.115    0.03969         34        896: 100% 455/455 [00:58<00:00,  7.79it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      31/99      2.06G    0.03675     0.1114    0.03753         53        736: 100% 455/455 [00:57<00:00,  7.85it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      32/99      2.06G    0.03719     0.1119    0.03716         39        800: 100% 455/455 [00:59<00:00,  7.66it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      33/99      2.06G    0.03679     0.1125     0.0368         55        832: 100% 455/455 [00:57<00:00,  7.92it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      34/99      2.06G    0.03669     0.1086    0.03522         32        672: 100% 455/455 [00:58<00:00,  7.74it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      35/99      2.06G     0.0356     0.1095    0.03383         29        576: 100% 455/455 [00:57<00:00,  7.89it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      36/99      2.06G    0.03599     0.1111    0.03412         36        832: 100% 455/455 [00:57<00:00,  7.97it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      37/99      2.06G    0.03675     0.1106    0.03324         34        544: 100% 455/455 [00:58<00:00,  7.73it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      38/99      2.06G    0.03542     0.1113    0.03225         49        384: 100% 455/455 [00:57<00:00,  7.93it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      39/99      2.06G    0.03629     0.1108    0.03151         62        544: 100% 455/455 [00:57<00:00,  7.86it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      40/99      2.06G    0.03566      0.108    0.03047         38        960: 100% 455/455 [00:57<00:00,  7.91it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      41/99      2.06G     0.0352     0.1118    0.03082         20        608: 100% 455/455 [00:58<00:00,  7.74it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      42/99      2.06G    0.03498     0.1086     0.0297         59        896: 100% 455/455 [00:57<00:00,  7.97it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      43/99      2.06G    0.03514     0.1084    0.02906         24        448: 100% 455/455 [00:56<00:00,  7.99it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      44/99      2.06G    0.03562     0.1112    0.02873         34        832: 100% 455/455 [00:57<00:00,  7.86it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      45/99      2.06G    0.03379      0.101    0.02778         38        576: 100% 455/455 [00:58<00:00,  7.80it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      46/99      2.06G    0.03503     0.1081    0.02775         38        768: 100% 455/455 [00:57<00:00,  7.95it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      47/99      2.06G    0.03461     0.1093     0.0271         35        672: 100% 455/455 [00:57<00:00,  7.91it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      48/99      2.06G    0.03377     0.1045     0.0265         55        608: 100% 455/455 [00:57<00:00,  7.91it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      49/99      2.06G    0.03435     0.1072    0.02699         50        864: 100% 455/455 [00:57<00:00,  7.90it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      50/99      2.06G    0.03363     0.1014    0.02614         44        352: 100% 455/455 [00:58<00:00,  7.76it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      51/99      2.06G    0.03335      0.104    0.02572         31        576: 100% 455/455 [00:58<00:00,  7.82it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      52/99      2.06G    0.03352     0.1022    0.02569         44        512: 100% 455/455 [00:58<00:00,  7.84it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      53/99      2.06G    0.03405     0.1053    0.02503         28        960: 100% 455/455 [00:58<00:00,  7.73it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      54/99      2.06G    0.03409     0.1067    0.02472         43        416: 100% 455/455 [00:58<00:00,  7.72it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      55/99      2.06G    0.03318     0.1055    0.02437         21        736: 100% 455/455 [00:59<00:00,  7.69it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      56/99      2.06G    0.03347      0.103    0.02416         62        864: 100% 455/455 [00:58<00:00,  7.76it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      57/99      2.06G    0.03407     0.1076    0.02425         23        672: 100% 455/455 [00:58<00:00,  7.76it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      58/99      2.06G    0.03313     0.1042    0.02395         31        704: 100% 455/455 [00:58<00:00,  7.84it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      59/99      2.06G    0.03332     0.1063    0.02333         16        768: 100% 455/455 [00:57<00:00,  7.85it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      60/99      2.06G    0.03226     0.1007    0.02299         40        800: 100% 455/455 [00:58<00:00,  7.75it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      61/99      2.06G    0.03331     0.1076    0.02294         16        704: 100% 455/455 [00:56<00:00,  8.02it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      62/99      2.06G    0.03244     0.1025    0.02325         45        640: 100% 455/455 [00:57<00:00,  7.93it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      63/99      2.06G    0.03259     0.1055    0.02266         45        736: 100% 455/455 [00:57<00:00,  7.87it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      64/99      2.06G    0.03356      0.104    0.02297         39        544: 100% 455/455 [00:57<00:00,  7.94it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      65/99      2.06G    0.03241      0.106    0.02178         28        704: 100% 455/455 [00:57<00:00,  7.88it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      66/99      2.06G    0.03308     0.1073    0.02264         27        352: 100% 455/455 [00:56<00:00,  8.09it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      67/99      2.06G    0.03301     0.1046    0.02172         20        544: 100% 455/455 [00:57<00:00,  7.93it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      68/99      2.06G    0.03249     0.1046    0.02175         44        768: 100% 455/455 [00:58<00:00,  7.76it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      69/99      2.06G    0.03188     0.1028    0.02135         50        640: 100% 455/455 [00:57<00:00,  7.89it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      70/99      2.06G    0.03217     0.1055    0.02164         56        768: 100% 455/455 [00:58<00:00,  7.74it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      71/99      2.06G     0.0319     0.1023    0.02082         44        640: 100% 455/455 [00:56<00:00,  7.99it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      72/99      2.06G    0.03161     0.1005    0.02058         48        800: 100% 455/455 [00:59<00:00,  7.68it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      73/99      2.06G    0.03159     0.1044    0.02066         22        704: 100% 455/455 [00:57<00:00,  7.97it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      74/99      2.06G    0.03017    0.09602    0.02054         23        704: 100% 455/455 [00:58<00:00,  7.81it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      75/99      2.06G    0.03156     0.1016    0.01938         17        864: 100% 455/455 [00:57<00:00,  7.86it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      76/99      2.06G    0.03073    0.09668    0.02003         44        896: 100% 455/455 [00:58<00:00,  7.72it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      77/99      2.06G    0.03022    0.09739    0.01922         21        672: 100% 455/455 [00:59<00:00,  7.60it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      78/99      2.06G    0.02983    0.09601    0.01918         33        800: 100% 455/455 [00:58<00:00,  7.82it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      79/99      2.06G    0.03096     0.1011    0.01971         28        640: 100% 455/455 [00:58<00:00,  7.79it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      80/99      2.06G    0.03067    0.09785    0.01916          9        320: 100% 455/455 [00:57<00:00,  7.96it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      81/99      2.06G     0.0305     0.1004    0.01929         41        384: 100% 455/455 [00:59<00:00,  7.60it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      82/99      2.06G    0.02981    0.09399    0.01896         28        352: 100% 455/455 [00:57<00:00,  7.91it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      83/99      2.06G    0.03056     0.1017    0.01957         66        736: 100% 455/455 [00:58<00:00,  7.76it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      84/99      2.06G    0.03028     0.1017    0.01913         33        544: 100% 455/455 [00:57<00:00,  7.93it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      85/99      2.06G    0.03075     0.1018    0.01864         31        672: 100% 455/455 [00:58<00:00,  7.84it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      86/99      2.06G    0.03001    0.09752    0.01861         32        352: 100% 455/455 [00:58<00:00,  7.77it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      87/99      2.06G    0.03092      0.104    0.01893         41        768: 100% 455/455 [00:57<00:00,  7.93it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      88/99      2.06G    0.03025     0.1008    0.01844         44        512: 100% 455/455 [00:57<00:00,  7.90it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      89/99      2.06G    0.03017    0.09843    0.01925         58        320: 100% 455/455 [00:57<00:00,  7.95it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      90/99      2.06G    0.02922    0.09513    0.01798         23        640: 100% 455/455 [00:59<00:00,  7.62it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      91/99      2.06G    0.02897    0.09518    0.01795         53        576: 100% 455/455 [00:57<00:00,  7.90it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      92/99      2.06G    0.02972     0.1005    0.01829         34        384: 100% 455/455 [00:57<00:00,  7.88it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      93/99      2.06G    0.03029     0.1019    0.01827         43        544: 100% 455/455 [00:58<00:00,  7.82it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      94/99      2.06G    0.02938     0.1004    0.01802         53        416: 100% 455/455 [00:57<00:00,  7.92it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      95/99      2.06G    0.03005     0.1029      0.018         41        832: 100% 455/455 [00:58<00:00,  7.82it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      96/99      2.06G    0.02986    0.09999    0.01789         23        320: 100% 455/455 [00:56<00:00,  8.07it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      97/99      2.06G    0.02923      0.096    0.01734         38        576: 100% 455/455 [00:57<00:00,  7.85it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      98/99      2.06G    0.02837    0.09336    0.01722         36        384: 100% 455/455 [00:58<00:00,  7.83it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      99/99      2.06G    0.02903    0.09705    0.01746         34        384: 100% 455/455 [00:57<00:00,  7.89it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 62/62 [00:05<00:00, 10.46it/s]\n",
      "                   all        248       2394      0.911      0.759      0.836      0.673\n",
      "\n",
      "100 epochs completed in 1.617 hours.\n",
      "Results saved to \u001b[1mruns/evolve/{colab_result}\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m1 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.91054,              0.75862,              0.83581,              0.67253,             0.022276,               0.1065,            0.0099266,                 0.01,                 0.01,                0.937,               0.0005,                    3,                  0.8,                  0.1,                 0.05,                  0.5,                    1,                    1,                    1,                  0.2,                    4,                    0,                0.015,                  0.7,                  0.4,                    0,                  0.1,                  0.5,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,                    3\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.91721, weight_decay=0.0006, warmup_epochs=2.91714, warmup_momentum=0.8, warmup_bias_lr=0.09612, box=0.05987, cls=0.48551, cls_pw=1.11699, obj=1.0, obj_pw=1.0329, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.01056, hsv_s=0.85451, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.50525, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.96867, mixup=0.0, copy_paste=0.0, anchors=2.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ğŸš€ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ğŸš€ runs in Comet\n",
      "Overriding model.yaml nc=80 with nc=36\n",
      "Overriding model.yaml anchors with anchors=2.0\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
      "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
      "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
      "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
      "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
      "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
      "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
      "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
      "  8                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
      "  9                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
      " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
      " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
      " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
      " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
      " 24      [17, 20, 23]  1    183926  models.yolo.Detect                      [36, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [320, 640, 1280]]\n",
      "Model summary: 445 layers, 86361366 parameters, 86361366 gradients, 205.1 GFLOPs\n",
      "\n",
      "Transferred 738/745 items from /content/yolov5/yolov5x.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "freezing model.0.conv.weight\n",
      "freezing model.0.bn.weight\n",
      "freezing model.0.bn.bias\n",
      "freezing model.1.conv.weight\n",
      "freezing model.1.bn.weight\n",
      "freezing model.1.bn.bias\n",
      "freezing model.2.cv1.conv.weight\n",
      "freezing model.2.cv1.bn.weight\n",
      "freezing model.2.cv1.bn.bias\n",
      "freezing model.2.cv2.conv.weight\n",
      "freezing model.2.cv2.bn.weight\n",
      "freezing model.2.cv2.bn.bias\n",
      "freezing model.2.cv3.conv.weight\n",
      "freezing model.2.cv3.bn.weight\n",
      "freezing model.2.cv3.bn.bias\n",
      "freezing model.2.m.0.cv1.conv.weight\n",
      "freezing model.2.m.0.cv1.bn.weight\n",
      "freezing model.2.m.0.cv1.bn.bias\n",
      "freezing model.2.m.0.cv2.conv.weight\n",
      "freezing model.2.m.0.cv2.bn.weight\n",
      "freezing model.2.m.0.cv2.bn.bias\n",
      "freezing model.2.m.1.cv1.conv.weight\n",
      "freezing model.2.m.1.cv1.bn.weight\n",
      "freezing model.2.m.1.cv1.bn.bias\n",
      "freezing model.2.m.1.cv2.conv.weight\n",
      "freezing model.2.m.1.cv2.bn.weight\n",
      "freezing model.2.m.1.cv2.bn.bias\n",
      "freezing model.2.m.2.cv1.conv.weight\n",
      "freezing model.2.m.2.cv1.bn.weight\n",
      "freezing model.2.m.2.cv1.bn.bias\n",
      "freezing model.2.m.2.cv2.conv.weight\n",
      "freezing model.2.m.2.cv2.bn.weight\n",
      "freezing model.2.m.2.cv2.bn.bias\n",
      "freezing model.2.m.3.cv1.conv.weight\n",
      "freezing model.2.m.3.cv1.bn.weight\n",
      "freezing model.2.m.3.cv1.bn.bias\n",
      "freezing model.2.m.3.cv2.conv.weight\n",
      "freezing model.2.m.3.cv2.bn.weight\n",
      "freezing model.2.m.3.cv2.bn.bias\n",
      "freezing model.3.conv.weight\n",
      "freezing model.3.bn.weight\n",
      "freezing model.3.bn.bias\n",
      "freezing model.4.cv1.conv.weight\n",
      "freezing model.4.cv1.bn.weight\n",
      "freezing model.4.cv1.bn.bias\n",
      "freezing model.4.cv2.conv.weight\n",
      "freezing model.4.cv2.bn.weight\n",
      "freezing model.4.cv2.bn.bias\n",
      "freezing model.4.cv3.conv.weight\n",
      "freezing model.4.cv3.bn.weight\n",
      "freezing model.4.cv3.bn.bias\n",
      "freezing model.4.m.0.cv1.conv.weight\n",
      "freezing model.4.m.0.cv1.bn.weight\n",
      "freezing model.4.m.0.cv1.bn.bias\n",
      "freezing model.4.m.0.cv2.conv.weight\n",
      "freezing model.4.m.0.cv2.bn.weight\n",
      "freezing model.4.m.0.cv2.bn.bias\n",
      "freezing model.4.m.1.cv1.conv.weight\n",
      "freezing model.4.m.1.cv1.bn.weight\n",
      "freezing model.4.m.1.cv1.bn.bias\n",
      "freezing model.4.m.1.cv2.conv.weight\n",
      "freezing model.4.m.1.cv2.bn.weight\n",
      "freezing model.4.m.1.cv2.bn.bias\n",
      "freezing model.4.m.2.cv1.conv.weight\n",
      "freezing model.4.m.2.cv1.bn.weight\n",
      "freezing model.4.m.2.cv1.bn.bias\n",
      "freezing model.4.m.2.cv2.conv.weight\n",
      "freezing model.4.m.2.cv2.bn.weight\n",
      "freezing model.4.m.2.cv2.bn.bias\n",
      "freezing model.4.m.3.cv1.conv.weight\n",
      "freezing model.4.m.3.cv1.bn.weight\n",
      "freezing model.4.m.3.cv1.bn.bias\n",
      "freezing model.4.m.3.cv2.conv.weight\n",
      "freezing model.4.m.3.cv2.bn.weight\n",
      "freezing model.4.m.3.cv2.bn.bias\n",
      "freezing model.4.m.4.cv1.conv.weight\n",
      "freezing model.4.m.4.cv1.bn.weight\n",
      "freezing model.4.m.4.cv1.bn.bias\n",
      "freezing model.4.m.4.cv2.conv.weight\n",
      "freezing model.4.m.4.cv2.bn.weight\n",
      "freezing model.4.m.4.cv2.bn.bias\n",
      "freezing model.4.m.5.cv1.conv.weight\n",
      "freezing model.4.m.5.cv1.bn.weight\n",
      "freezing model.4.m.5.cv1.bn.bias\n",
      "freezing model.4.m.5.cv2.conv.weight\n",
      "freezing model.4.m.5.cv2.bn.weight\n",
      "freezing model.4.m.5.cv2.bn.bias\n",
      "freezing model.4.m.6.cv1.conv.weight\n",
      "freezing model.4.m.6.cv1.bn.weight\n",
      "freezing model.4.m.6.cv1.bn.bias\n",
      "freezing model.4.m.6.cv2.conv.weight\n",
      "freezing model.4.m.6.cv2.bn.weight\n",
      "freezing model.4.m.6.cv2.bn.bias\n",
      "freezing model.4.m.7.cv1.conv.weight\n",
      "freezing model.4.m.7.cv1.bn.weight\n",
      "freezing model.4.m.7.cv1.bn.bias\n",
      "freezing model.4.m.7.cv2.conv.weight\n",
      "freezing model.4.m.7.cv2.bn.weight\n",
      "freezing model.4.m.7.cv2.bn.bias\n",
      "freezing model.5.conv.weight\n",
      "freezing model.5.bn.weight\n",
      "freezing model.5.bn.bias\n",
      "freezing model.6.cv1.conv.weight\n",
      "freezing model.6.cv1.bn.weight\n",
      "freezing model.6.cv1.bn.bias\n",
      "freezing model.6.cv2.conv.weight\n",
      "freezing model.6.cv2.bn.weight\n",
      "freezing model.6.cv2.bn.bias\n",
      "freezing model.6.cv3.conv.weight\n",
      "freezing model.6.cv3.bn.weight\n",
      "freezing model.6.cv3.bn.bias\n",
      "freezing model.6.m.0.cv1.conv.weight\n",
      "freezing model.6.m.0.cv1.bn.weight\n",
      "freezing model.6.m.0.cv1.bn.bias\n",
      "freezing model.6.m.0.cv2.conv.weight\n",
      "freezing model.6.m.0.cv2.bn.weight\n",
      "freezing model.6.m.0.cv2.bn.bias\n",
      "freezing model.6.m.1.cv1.conv.weight\n",
      "freezing model.6.m.1.cv1.bn.weight\n",
      "freezing model.6.m.1.cv1.bn.bias\n",
      "freezing model.6.m.1.cv2.conv.weight\n",
      "freezing model.6.m.1.cv2.bn.weight\n",
      "freezing model.6.m.1.cv2.bn.bias\n",
      "freezing model.6.m.2.cv1.conv.weight\n",
      "freezing model.6.m.2.cv1.bn.weight\n",
      "freezing model.6.m.2.cv1.bn.bias\n",
      "freezing model.6.m.2.cv2.conv.weight\n",
      "freezing model.6.m.2.cv2.bn.weight\n",
      "freezing model.6.m.2.cv2.bn.bias\n",
      "freezing model.6.m.3.cv1.conv.weight\n",
      "freezing model.6.m.3.cv1.bn.weight\n",
      "freezing model.6.m.3.cv1.bn.bias\n",
      "freezing model.6.m.3.cv2.conv.weight\n",
      "freezing model.6.m.3.cv2.bn.weight\n",
      "freezing model.6.m.3.cv2.bn.bias\n",
      "freezing model.6.m.4.cv1.conv.weight\n",
      "freezing model.6.m.4.cv1.bn.weight\n",
      "freezing model.6.m.4.cv1.bn.bias\n",
      "freezing model.6.m.4.cv2.conv.weight\n",
      "freezing model.6.m.4.cv2.bn.weight\n",
      "freezing model.6.m.4.cv2.bn.bias\n",
      "freezing model.6.m.5.cv1.conv.weight\n",
      "freezing model.6.m.5.cv1.bn.weight\n",
      "freezing model.6.m.5.cv1.bn.bias\n",
      "freezing model.6.m.5.cv2.conv.weight\n",
      "freezing model.6.m.5.cv2.bn.weight\n",
      "freezing model.6.m.5.cv2.bn.bias\n",
      "freezing model.6.m.6.cv1.conv.weight\n",
      "freezing model.6.m.6.cv1.bn.weight\n",
      "freezing model.6.m.6.cv1.bn.bias\n",
      "freezing model.6.m.6.cv2.conv.weight\n",
      "freezing model.6.m.6.cv2.bn.weight\n",
      "freezing model.6.m.6.cv2.bn.bias\n",
      "freezing model.6.m.7.cv1.conv.weight\n",
      "freezing model.6.m.7.cv1.bn.weight\n",
      "freezing model.6.m.7.cv1.bn.bias\n",
      "freezing model.6.m.7.cv2.conv.weight\n",
      "freezing model.6.m.7.cv2.bn.weight\n",
      "freezing model.6.m.7.cv2.bn.bias\n",
      "freezing model.6.m.8.cv1.conv.weight\n",
      "freezing model.6.m.8.cv1.bn.weight\n",
      "freezing model.6.m.8.cv1.bn.bias\n",
      "freezing model.6.m.8.cv2.conv.weight\n",
      "freezing model.6.m.8.cv2.bn.weight\n",
      "freezing model.6.m.8.cv2.bn.bias\n",
      "freezing model.6.m.9.cv1.conv.weight\n",
      "freezing model.6.m.9.cv1.bn.weight\n",
      "freezing model.6.m.9.cv1.bn.bias\n",
      "freezing model.6.m.9.cv2.conv.weight\n",
      "freezing model.6.m.9.cv2.bn.weight\n",
      "freezing model.6.m.9.cv2.bn.bias\n",
      "freezing model.6.m.10.cv1.conv.weight\n",
      "freezing model.6.m.10.cv1.bn.weight\n",
      "freezing model.6.m.10.cv1.bn.bias\n",
      "freezing model.6.m.10.cv2.conv.weight\n",
      "freezing model.6.m.10.cv2.bn.weight\n",
      "freezing model.6.m.10.cv2.bn.bias\n",
      "freezing model.6.m.11.cv1.conv.weight\n",
      "freezing model.6.m.11.cv1.bn.weight\n",
      "freezing model.6.m.11.cv1.bn.bias\n",
      "freezing model.6.m.11.cv2.conv.weight\n",
      "freezing model.6.m.11.cv2.bn.weight\n",
      "freezing model.6.m.11.cv2.bn.bias\n",
      "freezing model.7.conv.weight\n",
      "freezing model.7.bn.weight\n",
      "freezing model.7.bn.bias\n",
      "freezing model.8.cv1.conv.weight\n",
      "freezing model.8.cv1.bn.weight\n",
      "freezing model.8.cv1.bn.bias\n",
      "freezing model.8.cv2.conv.weight\n",
      "freezing model.8.cv2.bn.weight\n",
      "freezing model.8.cv2.bn.bias\n",
      "freezing model.8.cv3.conv.weight\n",
      "freezing model.8.cv3.bn.weight\n",
      "freezing model.8.cv3.bn.bias\n",
      "freezing model.8.m.0.cv1.conv.weight\n",
      "freezing model.8.m.0.cv1.bn.weight\n",
      "freezing model.8.m.0.cv1.bn.bias\n",
      "freezing model.8.m.0.cv2.conv.weight\n",
      "freezing model.8.m.0.cv2.bn.weight\n",
      "freezing model.8.m.0.cv2.bn.bias\n",
      "freezing model.8.m.1.cv1.conv.weight\n",
      "freezing model.8.m.1.cv1.bn.weight\n",
      "freezing model.8.m.1.cv1.bn.bias\n",
      "freezing model.8.m.1.cv2.conv.weight\n",
      "freezing model.8.m.1.cv2.bn.weight\n",
      "freezing model.8.m.1.cv2.bn.bias\n",
      "freezing model.8.m.2.cv1.conv.weight\n",
      "freezing model.8.m.2.cv1.bn.weight\n",
      "freezing model.8.m.2.cv1.bn.bias\n",
      "freezing model.8.m.2.cv2.conv.weight\n",
      "freezing model.8.m.2.cv2.bn.weight\n",
      "freezing model.8.m.2.cv2.bn.bias\n",
      "freezing model.8.m.3.cv1.conv.weight\n",
      "freezing model.8.m.3.cv1.bn.weight\n",
      "freezing model.8.m.3.cv1.bn.bias\n",
      "freezing model.8.m.3.cv2.conv.weight\n",
      "freezing model.8.m.3.cv2.bn.weight\n",
      "freezing model.8.m.3.cv2.bn.bias\n",
      "freezing model.9.cv1.conv.weight\n",
      "freezing model.9.cv1.bn.weight\n",
      "freezing model.9.cv1.bn.bias\n",
      "freezing model.9.cv2.conv.weight\n",
      "freezing model.9.cv2.bn.weight\n",
      "freezing model.9.cv2.bn.bias\n",
      "freezing model.10.conv.weight\n",
      "freezing model.10.bn.weight\n",
      "freezing model.10.bn.bias\n",
      "freezing model.13.cv1.conv.weight\n",
      "freezing model.13.cv1.bn.weight\n",
      "freezing model.13.cv1.bn.bias\n",
      "freezing model.13.cv2.conv.weight\n",
      "freezing model.13.cv2.bn.weight\n",
      "freezing model.13.cv2.bn.bias\n",
      "freezing model.13.cv3.conv.weight\n",
      "freezing model.13.cv3.bn.weight\n",
      "freezing model.13.cv3.bn.bias\n",
      "freezing model.13.m.0.cv1.conv.weight\n",
      "freezing model.13.m.0.cv1.bn.weight\n",
      "freezing model.13.m.0.cv1.bn.bias\n",
      "freezing model.13.m.0.cv2.conv.weight\n",
      "freezing model.13.m.0.cv2.bn.weight\n",
      "freezing model.13.m.0.cv2.bn.bias\n",
      "freezing model.13.m.1.cv1.conv.weight\n",
      "freezing model.13.m.1.cv1.bn.weight\n",
      "freezing model.13.m.1.cv1.bn.bias\n",
      "freezing model.13.m.1.cv2.conv.weight\n",
      "freezing model.13.m.1.cv2.bn.weight\n",
      "freezing model.13.m.1.cv2.bn.bias\n",
      "freezing model.13.m.2.cv1.conv.weight\n",
      "freezing model.13.m.2.cv1.bn.weight\n",
      "freezing model.13.m.2.cv1.bn.bias\n",
      "freezing model.13.m.2.cv2.conv.weight\n",
      "freezing model.13.m.2.cv2.bn.weight\n",
      "freezing model.13.m.2.cv2.bn.bias\n",
      "freezing model.13.m.3.cv1.conv.weight\n",
      "freezing model.13.m.3.cv1.bn.weight\n",
      "freezing model.13.m.3.cv1.bn.bias\n",
      "freezing model.13.m.3.cv2.conv.weight\n",
      "freezing model.13.m.3.cv2.bn.weight\n",
      "freezing model.13.m.3.cv2.bn.bias\n",
      "freezing model.14.conv.weight\n",
      "freezing model.14.bn.weight\n",
      "freezing model.14.bn.bias\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 123 weight(decay=0.0), 126 weight(decay=0.0006), 126 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /tmp/dataset/train/labels.cache... 892 images, 19 backgrounds, 0 corrupt: 100% 910/910 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.4GB ram): 100% 910/910 [00:00<00:00, 1182.26it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /tmp/dataset/val/labels.cache... 248 images, 0 backgrounds, 0 corrupt: 100% 248/248 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset âš ï¸, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 8548 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9102: 100% 1000/1000 [00:01<00:00, 692.52it/s]\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 6.00 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.767/0.910-mean/best, past_thr=0.767-mean: 39,70, 47,81, 43,97, 51,89, 50,116, 70,120\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone âœ… (optional: update model *.yaml to use these anchors in the future)\n",
      "Plotting labels to runs/evolve/{colab_result}/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/evolve/{colab_result}\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/99      2.07G     0.1031     0.1767    0.09273         33        544: 100% 455/455 [01:02<00:00,  7.31it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/99      2.07G    0.08848      0.143    0.08416         45        768: 100% 455/455 [00:58<00:00,  7.76it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/99      2.07G    0.08722     0.1399    0.08269         29        896: 100% 455/455 [00:57<00:00,  7.88it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/99      2.07G    0.07645     0.1345    0.08154         61        928: 100% 455/455 [00:58<00:00,  7.76it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/99      2.07G     0.0694      0.132    0.08017         48        736: 100% 455/455 [00:58<00:00,  7.80it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/99      2.07G     0.0649     0.1342    0.07776         37        608: 100% 455/455 [00:57<00:00,  7.97it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/99      2.07G    0.06136     0.1294    0.07532         28        960: 100% 455/455 [00:58<00:00,  7.83it/s]\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/99      2.07G    0.06058     0.1259     0.0734         36        928:  72% 329/455 [00:43<00:17,  7.03it/s]"
     ]
    }
   ],
   "source": [
    "# Train the model with fine tuning\n",
    "\n",
    "!python3 /content/yolov5/train.py  --batch 2 --epochs 100  --data '/content/yolov5/dataset.yaml' --weights /content/yolov5/yolov5x.pt\\\n",
    "--freeze 17 --multi-scale --evolve 1000 --patience 20 --workers 4 --cache --name {colab_result}  --resume True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1R_Gju0uBi_K"
   },
   "source": [
    "# New section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55LSA19FxcWl"
   },
   "source": [
    "**Fine Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYL6pBvZplSu"
   },
   "outputs": [],
   "source": [
    "!python3 /content/yolov5/train.py  --hyp /content/yolov5/data/hyps/hyp.scratch-high.yaml  --batch 2 --epochs 100  --data '/content/yolov5/dataset.yaml' --weights yolov5x.pt\\\n",
    "--freeze 17 --multi-scale --evolve 100 --patience 50 --workers 4 --cache --name {colab_result} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFQiyv8EplT6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvoixkW8p9CR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFTTBJZDp9Ei"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ny9TYsDp9KN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JBSEoO6Pxr1-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cKBZE6Kxr4w"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
